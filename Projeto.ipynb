{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Projeto | Construido uma rede com jogos da Steam üéÆÔ∏è\n",
    "\n",
    "    \n",
    "---------------------\n",
    "\n",
    "**Equipe**\n",
    "\n",
    "\n",
    " * Let√≠cia Co√™lho Barbosa       | [Github](https://github.com/leticiacb1)\n",
    " <br>\n",
    "\n",
    " * L√≠dia Alves Chagas Domingos  | [Github](https://github.com/LidiaDomingos)\n",
    " <br>\n",
    "\n",
    " * Lorran Caetano Lopes         | [Github](https://github.com/lorrancmlopes)\n",
    " <br>\n",
    " \n",
    " ---------------------\n",
    "\n",
    "* **Dataset escolhido** : [Jogos da Steam](https://www.kaggle.com/datasets/fronkongames/steam-games-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O DATASET\n",
    "\n",
    "-------\n",
    "\n",
    "O contexto do projeto engloba os jogos famosos para computadores dispon√≠veis na Steam. Atualmente, a plataforma Steam possui aproximadamente 95 milh√µes de usu√°rios no mundo todo e √© sucesso entre os gamers, sendo a atual l√≠der do mercado. \n",
    "\n",
    "\n",
    "#### Principais colunas\n",
    "<br>\n",
    "\n",
    "O dataset escolhido possui 39 colunas, nesse t√≥pico citaremos a descri√ß√µes de algumas colunas de maior interesse para analise.\n",
    "\n",
    "* **name** : nome do jogo.\n",
    "<br>\n",
    "\n",
    "* **releaseDate** : data de lan√ßamento.\n",
    "<br>\n",
    "\n",
    "* **price** : pre√ßo do jogo.\n",
    "<br>\n",
    "\n",
    "* **metacritic_score** : media das notas dadas por avalia√ß√µes de profissionais.\n",
    "<br>\n",
    "\n",
    "* **user_score** : media das notas dadas pelos usu√°rios do jogo.\n",
    "<br>\n",
    "\n",
    "* **score_rank** : o ranke do jogo baseado nas avalia√ß√µes dos usu√°rios.\n",
    "<br>\n",
    "\n",
    "* **developers** : desenvolvedores dos jogos.\n",
    "<br>\n",
    "\n",
    "* **categories** : categoria dos jogos.\n",
    "<br>\n",
    "\n",
    "* **genres** : genero do jogo.\n",
    "<br>\n",
    "\n",
    "* **tags** : Tags do jogo.\n",
    "<br>\n",
    "\n",
    " \n",
    " ### NOSSA REDE\n",
    "\n",
    "-------\n",
    "\n",
    "* **V√©rtices** : Jogos da Steam.\n",
    "<br>\n",
    "\n",
    "* **Arestas**  : Existe uma aresta entre um jogo 1 e um jogo 2 se o n√∫mero de tags em comum entre os jogos for superior ou igual a um **threadhold** (definido mais a frente)\n",
    "\n",
    "\n",
    " ### HIPOTESE\n",
    "\n",
    "-------\n",
    "\n",
    "\n",
    "`\"Quanto mais central √© a sua posi√ß√£o na rede, maior a m√©dia de avalia√ß√µes dos cr√≠ticos profissionais.\"`\n",
    "<br>\n",
    "\n",
    "* **Vari√°vel de controle**: Tamanho da empresa.\n",
    "<br>\n",
    "\n",
    "* **Vari√°vel dependente**:  medida indicativa de centralidade do n√≥ na rede (coreness).\n",
    "<br>\n",
    "\n",
    "* **Vari√°vel independente**: dataset[Metacritic score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando os dados \n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# ------------ IMPORTS ------------\n",
    "# ---------------------------------\n",
    "\n",
    "import seaborn as sns\n",
    "from netpixi.integration.gt import *\n",
    "from regression.integration.gt import *\n",
    "import netpixi\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import regression as reg\n",
    "\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cpnet\n",
    "from graph_tool import spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafo n√£o direcional | Informa√ß√£o obtida via documenta√ß√£o\n",
    "g = Graph(directed=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ----  Lendo o arquivo ----\n",
    "\n",
    "df_principal = pd.read_csv('games.csv')\n",
    "\n",
    "columns = [col for col in df_principal.columns]\n",
    "\n",
    "print(f\"\\n> Colunas : {columns}\\n\")\n",
    "\n",
    "print(f\"\\n> Tamanho do dataset : {df_principal.shape}\\n\")\n",
    "\n",
    "print(f\"\\n> Primeiras linhas dataset : \\n\")\n",
    "df_principal.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Descrevendo melhor a coluna Metacritic score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n> Valores √∫nicos presentes:\\n\\n {df_principal['Metacritic score'].unique()}\\n\")\n",
    "\n",
    "print(f\"\\n> Distribui√ß√£o dos valores :\\n\\n {df_principal['Metacritic score'].value_counts()}\\n\")\n",
    "\n",
    "print(f\"\\n> Descri√ß√£o:\\n\\n{df_principal['Metacritic score'].describe()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpando Dataset\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Retirando alguns valores nulos ----\n",
    "\n",
    "df_principal.dropna(subset=['Tags', 'Metacritic score'], inplace=True)\n",
    "df_principal = df_principal[df_principal['Metacritic score'] != 0]\n",
    "\n",
    "\n",
    "# ---- Amostragem para anos > 2019 e < 2023 ----\n",
    "\n",
    "df_principal = df_principal[ df_principal[\"Release date\"].map(lambda date: \n",
    "                                                              ((int(date.split(' ')[-1]) > 2020) and \n",
    "                                                               int(date.split(' ')[-1]) < 2023))== True]\n",
    "df_principal.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "print(f\"\\n> Tamanho do dataset p√≥s limpeza:\\n {df_principal.shape}\\n\")\n",
    "\n",
    "print(f\"\\n> Descri√ß√£o coluna Metacritic score:\\n\\n {df_principal['Metacritic score'].describe()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset auxiliar de total_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_revenue = pd.read_csv('total_revenue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ausentes = []\n",
    "presentes = []\n",
    "\n",
    "# Verificando se cada valor da coluna do df1 est√° presente no df2\n",
    "for publi in df_principal['Publishers'].tolist():\n",
    "    if publi.lower() not in [name.lower() for name in df_total_revenue[\"Name\"].tolist()]:\n",
    "        if publi.lower() not in [name.lower() for name in ausentes]:\n",
    "            print(publi)\n",
    "            ausentes.append(publi)\n",
    "    else:\n",
    "        if publi.lower() not in [name.lower() for name in presentes]:\n",
    "            presentes.append(publi)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Verificar se cada valor da coluna 'Publishers' do df_principal est√° presente no df_total_revenue\n",
    "for index, row in df_principal.iterrows():\n",
    "    publishers = row['Publishers']\n",
    "    total_revenue = 0\n",
    "    \n",
    "    # Verificar se o valor de 'publishers' est√° presente na coluna 'Name' do df_total_revenue\n",
    "    for name in publishers.split(','):\n",
    "        mask = df_total_revenue['Name'].str.lower() == name.lower().strip()\n",
    "        revenue = df_total_revenue.loc[mask, 'Total revenue'].sum()\n",
    "        total_revenue += revenue\n",
    "    \n",
    "    # Inserir o valor total de receita na coluna 'Total revenue' do df_principal\n",
    "    df_principal.at[index, 'Total revenue'] = total_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset auxiliar de total_revenue (baixe [aqui](https://drive.google.com/file/d/1DUGhWPNJdPr30eo1oCH9RUPlG_FMHr3L/view?usp=sharing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_revenue = pd.read_csv('total_revenue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ausentes = []\n",
    "presentes = []\n",
    "\n",
    "# Verificando se cada valor da coluna do df1 est√° presente no df2\n",
    "for publi in df_principal['Publishers'].tolist():\n",
    "    if publi.lower() not in [name.lower() for name in df_total_revenue[\"Name\"].tolist()]:\n",
    "        if publi.lower() not in [name.lower() for name in ausentes]:\n",
    "            print(publi)\n",
    "            ausentes.append(publi)\n",
    "    else:\n",
    "        if publi.lower() not in [name.lower() for name in presentes]:\n",
    "            presentes.append(publi)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Verificar se cada valor da coluna 'Publishers' do df_principal est√° presente no df_total_revenue\n",
    "for index, row in df_principal.iterrows():\n",
    "    publishers = row['Publishers']\n",
    "    total_revenue = 0\n",
    "    \n",
    "    # Verificar se o valor de 'publishers' est√° presente na coluna 'Name' do df_total_revenue\n",
    "    for name in publishers.split(','):\n",
    "        mask = df_total_revenue['Name'].str.lower() == name.lower().strip()\n",
    "        revenue = df_total_revenue.loc[mask, 'Total revenue'].sum()\n",
    "        total_revenue += revenue\n",
    "    \n",
    "    # Inserir o valor total de receita na coluna 'Total revenue' do df_principal\n",
    "    df_principal.at[index, 'Total revenue'] = total_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Tranforma a coluna de Tags em lista ----\n",
    "\n",
    "df_principal['Tags'] = df_principal.Tags.apply(lambda x: str(x).split(','))\n",
    "print(f\"\\n> dataset[Tags] como lista:\\n\\n{df_principal['Tags']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando os N√≥s da Rede\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 0\n",
    "unique_name_values = df_principal['Name'].unique().tolist()\n",
    "node_data = []\n",
    "\n",
    "for _ , linha in  df_principal.iterrows():\n",
    "    \n",
    "    if(linha['Name'] in unique_name_values):\n",
    "        node_data.append([id ,linha['Tags'], linha['Metacritic score']])\n",
    "        id+=1\n",
    "\n",
    "df_nodes = pd.DataFrame(node_data,columns=['id','Tags', 'Metacritic score']) \n",
    "df_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Criando os n√≥s e adiciona atributos aos n√≥s ----\n",
    "\n",
    "g.add_vp('Metacritic score')\n",
    "\n",
    "aux = []\n",
    "for _, infos in df_nodes.iterrows():\n",
    "    \n",
    "    #Adiciona v√©rtices:\n",
    "    infos = infos.astype(object)\n",
    "    g.add_vertex(infos['id'])\n",
    "    \n",
    "    # Adiciona atributos:\n",
    "    vertice = g.get_vertex(infos['id'])\n",
    "    vertice['Metacritic score'] = infos['Metacritic score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando as Arestas da Rede\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tags(lista_tags_1, lista_tags_2):\n",
    "    '''\n",
    "    Retorna o n√∫mero de tags em comum entre duas listas\n",
    "    '''    \n",
    "    count_common_tags = 0\n",
    "        \n",
    "    for tag1 in lista_tags_1:\n",
    "        for tag2 in lista_tags_2:\n",
    "            \n",
    "            if(tag1 == tag2):\n",
    "                count_common_tags+=1\n",
    "    \n",
    "    return count_common_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_relation = set()\n",
    "data_relation = set()\n",
    "\n",
    "for _, linha1 in df_nodes.iterrows():\n",
    "    for _,linha2 in df_nodes.iterrows():\n",
    "        \n",
    "        proximidade = 0\n",
    "        \n",
    "        if(( (linha1['id'] , linha2['id']) not in node_relation) and \n",
    "           ( (linha2['id'] , linha1['id']) not in node_relation) and (linha2['id'] != linha1['id'])):\n",
    "            \n",
    "            # Calculando TAGS em comum\n",
    "            proximidade = count_tags(linha1['Tags'], linha2['Tags'])\n",
    "            \n",
    "            # Adiciona valor na rela√ß√£o de n√≥s:\n",
    "            node_relation.add((linha1['id'] , linha2['id']))\n",
    "        \n",
    "            data_relation.add((linha1['id'], linha2['id'], proximidade))\n",
    "            \n",
    "df_relation = pd.DataFrame(data_relation,columns=['node_1', 'node_2' , 'Tags_em_Comum'] ) \n",
    "df_relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threadhold para a constru√ß√£o das Arestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relation['Tags_em_Comum'][df_relation['Tags_em_Comum'] != 0].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Escolhendo threshold par aa cria√ß√£o das arestas a depender da distribui√ß√£o ----\n",
    "\n",
    "threshold_proximidade = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Criando arestas ----\n",
    "\n",
    "for _ , relacao in df_relation.iterrows():\n",
    "    \n",
    "    if(relacao['Tags_em_Comum'] > threshold_proximidade):\n",
    "        g.add_edge(relacao['node_1'], relacao['node_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M√©tricas da Rede\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- N√∫mero de arestas, n√≥s e densidade ----\n",
    "\n",
    "n = g.num_vertices()\n",
    "m = g.num_edges()\n",
    "\n",
    "if g.is_directed():\n",
    "    max_edges = n * (n - 1)\n",
    "else:\n",
    "    max_edges = n * (n - 1) // 2\n",
    "d = m / max_edges\n",
    "\n",
    "print('\\n > N√∫mero de v√©rtices de g:', n )\n",
    "print('\\n > N√∫mero de arestas de g:', m)\n",
    "print('\\n > Densidade:', d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando Degree\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propriedade dos v√©rtices\n",
    "data = gt_data(g)\n",
    "\n",
    "# Calculando degrees\n",
    "in_degrees = []\n",
    "out_degrees = []\n",
    "degrees = []\n",
    "\n",
    "for v in g.all_vertices():\n",
    "    in_degrees.append(v.in_degree())\n",
    "for v in g.all_vertices():\n",
    "    out_degrees.append(v.out_degree())\n",
    "for v in g.all_vertices():\n",
    "    degrees.append(v.total_degree())\n",
    "    \n",
    "data['in_degree'] = in_degrees\n",
    "data['out_degree'] = out_degrees\n",
    "data['degree'] = degrees\n",
    "data['degree'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data['degree'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafo\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Salva e renderiza grafo -----\n",
    "gt_save(g, 'projeto.net.gz')\n",
    "\n",
    "r = netpixi.render('/projeto.net.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Algoritmo Reingold Fruchterm -----\n",
    "m = gt_draw.fruchterman_reingold_layout(g)\n",
    "gt_move(g, m)\n",
    "gt_save(g, 'projeto_frunch.net.gz')\n",
    "r = netpixi.render('projeto_frunch.net.gz');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_int_coreness = []\n",
    "lista_float_coreness = []\n",
    "\n",
    "# Adiciona propriedades ao n√≥\n",
    "g.add_vp('core')\n",
    "g.add_vp('coreness')\n",
    "\n",
    "# ---- Fun√ß√µes ----\n",
    "\n",
    "def surprise():\n",
    "    matrix = spectral.adjacency(g)\n",
    "    algorithm = cpnet.Surprise()\n",
    "    algorithm.detect(matrix)\n",
    "    return algorithm.get_coreness()\n",
    "\n",
    "def rombach():\n",
    "    matrix = spectral.adjacency(g)\n",
    "    algorithm = cpnet.Rombach()\n",
    "    algorithm.detect(matrix)\n",
    "    return algorithm.get_coreness()\n",
    "\n",
    "# ---- Roda Algor√≠timo ----\n",
    "c_core = surprise()\n",
    "c_coreness = rombach()\n",
    "\n",
    "\n",
    "for i, coreness in c_core.items():\n",
    "    v = g.get_vertex_by_index(i)\n",
    "    v['core'] = int(coreness)\n",
    "    lista_int_coreness.append(int(coreness))\n",
    "df_nodes['core'] = lista_int_coreness\n",
    "\n",
    "for i, coreness in c_coreness.items():\n",
    "    v = g.get_vertex_by_index(i)\n",
    "    v['coreness'] = float(coreness)\n",
    "    lista_float_coreness.append(float(coreness))\n",
    "df_nodes['coreness'] = lista_float_coreness\n",
    "\n",
    "\n",
    "# ---- Modifica cor ----\n",
    "for v in g.all_vertices():\n",
    "    if v['core'] == 1:\n",
    "        r.vertex(v['id'], color=0xff0000)\n",
    "    else:\n",
    "        r.vertex(v['id'], color=0x00ff00)\n",
    "        \n",
    "# ---- Modifica tamanho ----\n",
    "\n",
    "for v in g.all_vertices():\n",
    "    r.vertex(v['id'], size=(10 + 40 * v['coreness']))\n",
    "    r.vertex(v['Metacritic score'], color=0xff0000)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regress√£o Linear\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Metacritc Score name\n",
    "df_nodes.rename(columns = {'Metacritic score':'MetacriticScore'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df_nodes['coreness'], y=df_nodes['MetacriticScore']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df_nodes['coreness'], y=df_nodes['MetacriticScore']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = reg.linear(data=df_nodes, formula=\" MetacriticScore ~ coreness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.micro_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot_residuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observa-se um treshold de divis√£o no coreness, dessa forma, podemos dividir esses dados em dois conjuntos\n",
    "# E assim aplicar uma regress√£o em cada metade.\n",
    "\n",
    "threshold_coreness = 0.5\n",
    "\n",
    "df_nodes_menor = df_nodes[df_nodes['coreness'] < threshold_coreness]\n",
    "df_nodes_maior =  df_nodes[df_nodes['coreness'] > threshold_coreness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes_menor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes_maior.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Para a primeira metade  -------\n",
    "\n",
    "sns.regplot(x=df_nodes_menor['coreness'], y=df_nodes_menor['MetacriticScore']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_menor = reg.linear(data=df_nodes_menor, formula='MetacriticScore ~ coreness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_menor.micro_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_menor.plot_residuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Para a segunda metade  -------\n",
    "\n",
    "sns.regplot(x=df_nodes_maior['coreness'], y=df_nodes_maior['MetacriticScore']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_maior = reg.linear(data=df_nodes_maior, formula='MetacriticScore ~ coreness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_maior.micro_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_menor.plot_residuals()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
